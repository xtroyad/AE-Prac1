---
title: "Práctica de Aprendizaje Estadístico - Parte 1"
author: " "
date: "2024-10-30"
---

# 0. Carga los datos y elimina la variable TRAIN.

## 0.1 Configuración inicial. Carga de librerías.

**Nota: Nos aseguramos de tener el paquete `ElemStatLearn` instalado. Si no: `install.packages(lib_URL)`**

```{r}

lib_URL = 'https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/ElemStatLearn_2015.6.26.2.tar.gz'
# install.packages(lib_URL)

library(ElemStatLearn)
library(dplyr)
```

Utilizamos `head()` para ver las primeras filas y hacernos una idea de las variables disponibles

```{r }

data("prostate", package = "ElemStatLearn")
head(prostate)

```

## 0.2 Eliminación de datos `TRAIN`.

La columna `train` se utiliza en estudios previos para indicar las filas de entrenamiento.

Dado que esta práctica no la requiere, eliminamos esta columna para simplificar el conjunto de datos.

```{r}

prostate = prostate %>% select(-train)
head(prostate)
```

# 1. Exploración de los datos

## 1.1 ¿Cuántas variables hay?

Tras eliminar la columna `train`, contamos con un total de `r length(prostate)` variables.

## 1.2 ¿De qué clase son?

Utilizamos la función `sapply` para aplicar una función, en este caso `class`, a todas las columnas.

```{r}
sapply(prostate, class)
```

Los tipos de las variables son del tipo `numeric` e `integer`, por lo que todos datos son números. Dado que son datos numéricos, podemos echar un vistazo a sus distribuciones.

```{r}
par(mfrow=c(3,3))
for (column in names(prostate)) {
  hist(prostate[[column]], main=paste("Histograma de", column), xlab = column)
}
```

Podemos observar que los valores de la variable `svi` se concentran en el 0 y en el 1, indicador de que esta variable podría ser un *booleano*. Veamos si estos son sus únicos valores.

```{r}
unique(prostate$svi)
```

0 y 1 son los únicos valores presentes, por lo que confirmaríamos que se trata de una variable *booleana* donde 1 indicaría que el cáncer ha invadido el vesículo seminal, y 0 indicaría lo contrario.

## 1.3 ¿Hay una variable que correspondiente al identificador de paciente? Si es así, elimínala.

No existe ninguna variable con el identificador del paciente.

## 1.4 ¿Hay valores nulos en alguno de los ficheros?

Averiguamos si existe algún valor nulo en todo el conjunto de datos. En caso de que lo haya, identificamos las columnas que los contienen.

```{r}
any(is.na(prostate))
```

Dado que no hay ningún valor nulo en nuestro set de datos, continuamos.

## ¿Están estandarizadas las variables? En este punto del análisis, ¿es necesario normalizarlas?

Tras revisar los histogramas realizados en el subapartado 2 podemos concluir que, dados los rangos de las variables y su disposición, estos no se encuentran normalizados.

## ¿Por qué crees que algunas variables están es escala logarítmica?

El objetivo de poner algunas de las variables en escala logarítmica es el de facilitar su posterior análisis por varios motivos:

- Reducir la asimetría en casos en los que la distribución está muy sobrecargada en uno de sus extremos donde algunos valores excepcionales distorsionarían las estadísticas de la variable, haciendo que sus distribuciones se asemejen más a las de una distribución normal (como se observa en `lcavol`, `lweight` y `lpsa`).
- Hacer que algunas variables se comporten de forma lineal cuando en escala natural no lo harían.

Además, cabe añadir que en los campos de la biología y la química es común usar escalas logarítmicas cuando estas hacen más fácil la interpretación de los datos.

# 2. Análisis de variables categóricas

Para convertir las variables `svi` y `gleason` a categóricas usamos la función `factor`. 

```{r}
prostate$svi <- factor(prostate$svi)
prostate$gleason <- factor(prostate$gleason)
```

A continuación, visualizamos las distribuciones usando gráficos de barras:

```{r}
par(mfrow = c(1, 2))  # Ajustar disposición gráfica
barplot(table(prostate$svi), main = "Distribución de SVI", col = "lightblue")
barplot(table(prostate$gleason), main = "Distribución de Gleason", col = "lightgreen")
```

Se puede observar como para la mayoría de pacientes se indica que el cáncer no ha invadido la vesícula seminal, a la par que la mayoría tiene un índice de Gleason de 6 o 7. Esto puede indicar cierta relación, ya que el índice de Gleason mide la agresividad del cáncer, por lo que índices más bajos indican cánceres menos agresivos. Podríamos aventurarnos a pensar que la mayoría de cánceres agresivos no llegarían a infectar la vesícula seminal.

En el caso de la variable **Edad** queremos hacer una agrupación cada 5 años, por lo que usaremos la función `cut` para generar esas categorías:

```{r}
max.age = max(prostate$age)
min.age = min(prostate$age)
# Añadimos +5 al maximo para que el rango tome tambien el ultimo grupo
prostate$age <- cut(prostate$age, breaks = seq(from=min.age, to=max.age+5, by=5), right=FALSE)
barplot(table(prostate$age), main = "Distribución de Edad", col = "salmon", width = 3)
```

En el caso de la edad nos encontramos una distribución que podría recordar a la normal, centrada en los 65 años, encontrándose el grueso de la distribución entre los 61 y 70 años. Cabe añadir que encontramos casos desde los `r min.age` hasta los `r max.age` años.

# 3. Análisis de frecuencias

## ¿Qué porcentaje de pacientes con la puntuación de Gleason igual a 7, presenta índice igual svi igual a 0?

```{r}
# Filtramos por gleason = 7
gleason.7 <- subset(prostate, gleason == 7)
svi.pct0 <- sum(gleason.7$svi == 0) / nrow(gleason.7) * 100
svi.pct0.r = round(svi.pct0)
svi.pct0
```

Por lo tanto, un `r svi.pct0.r`% de los pacientes con índice de Gleason igual a 7 presenta un `svi` de 0.

## ¿Qué porcentaje de pacientes con índice svi igual a 0 tiene la puntuación de Gleason igual a 7?

```{r}
# Filtramos por gleason = 7
svi.0 <- subset(prostate, svi == 0)
# En el apartado anterior cambiamos svi=0 por la categoría No
gleason.pct7 <- sum(svi.0$gleason == 7) / nrow(svi.0) * 100
gleason.pct7.r = round(gleason.pct7)
gleason.pct7
```

Por lo tanto, un `r gleason.pct7.r`% de los pacientes con un `svi` de 0 presenta un índice de Gleason igual a 7.

## Estas dos variables, ¿son independientes?

Vistos los resultados de estos dos últimos subapartados, podemos pensar que estas variables están relacionadas. Además, ya en el apartado 2 se vio como también podría existir una posible relación entre las variables y se le trató de dar una explicación lógica. 

Para probar si realmente existe esta relación entre variables, exponemos los datos a un test de independencia *chi cuadrado*, cuya implementación en R es simple y rápida. En este test queremos probar que las variables están relacionadas, lo cual es nuestra hipótesis $H_1$, por lo que la hipótesis nula $H_0$ será que estas son independientes:

```{r}
contingencia.svi_gleason <- table(prostate$gleason, prostate$svi)
chi_test <- chisq.test(contingencia.svi_gleason)
chi_test
```

Al realizar el test, obtenemos un $p$-valor de 0.0012. Dado que los niveles de significación más comunes son $0.05$ y $0.01$, y nuestro $p$-valor es notablemente menor, podemos afirmar con seguridad que existe una relación entre estas variables.

# 4. Regresión lineal simple.

Análisis de la dependencia lineal de la variable `lpsa` con la variable `lcavol`.

```{r}
library(dplyr)
library(ggplot2)
```

Ajustamos el modelo y vemos su `summary()`:

```{r}
modelo_lineal <- lm(lpsa ~ lcavol, data = prostate)

summary(modelo_lineal)
```

## 4.1 Interpretación del Modelo Lineal calculado

### Ecuación del Modelo

La ecuación del modelo de regresión lineal es: 

$$
\text{lpsa} = 1.50730 + 0.71932 \cdot \text{lcavol}
$$

### Intercepto ($\beta_0$)

-   El intercepto de **1.50730** indica el valor estimado de `lpsa` cuando `lcavol` es igual a 0.

### Pendiente ($\beta_1$)

-   El coeficiente para `lcavol` es **0.71932**. Esto sugiere que, por cada unidad de incremento en `lcavol`, se espera que `lpsa` aumente en aproximadamente **0.71932** unidades.

### Residuos

-   Estadísticas de los residuos:
    -   **Mínimo**: -1.67624
    -   **Máximo**: 1.89672
-   Esto indica variaciones en los errores de predicción.

### Error Estándar de los Residuos

-   El error estándar de los residuos es **0.7875**, indicando que las predicciones están, en promedio, a **0.7875** unidades de `lpsa` de los valores reales.

### R-squared (R²)

-   El $R^2$ múltiple es **0.5394**, lo que significa que aproximadamente el **53.94%** de la variabilidad en `lpsa` se puede explicar por la variabilidad en `lcavol`.

### F-statistic

-   El valor de la estadística F es **111.3** con un valor p-value a **2.2e-16**, indicando que al menos uno de los predictores tiene un efecto significativo en `lpsa`.

### Conclusión

En resumen, el modelo de regresión lineal simple muestra que hay una relación positiva y significativa entre `lcavol` y `lpsa`. A medida que el logaritmo del volumen del cáncer (`lcavol`) aumenta, también se espera que el logaritmo del antígeno prostático específico (`lpsa`) aumente. El modelo es estadísticamente significativo.

## 4.2 Plot de los datos junto a la recta de regresión.

Crearemos una gráfico de dispersión de `lcavol` vs `lpsa`.

```{r}
ggplot(prostate, 
       aes(x = lcavol, y = lpsa)) +
  
 # Puntos de los datos
geom_point(color = "blue", 
           alpha = 0.4) +

# Recta de regresión
geom_smooth(method = "lm", 
            color = "red") + 
  
labs(title = "Relación entre lcavol y lpsa",
     x = "Log de Volumen de Cáncer (lcavol)",
     y = "Log de Antígeno Prostático Específico (lpsa)") +
  
theme_minimal()
```

## 4.3 Intervalos de confianza para los coeficientes del modelo con una confianza de 0.95.

Los intervalos de confianza al 95% para los coeficientes del modelo son importantes para entender la precisión de las estimaciones. A continuación se presentan los intervalos calculados:

```{r}
confint(modelo_lineal, level = 0.95)
```

-   **Intercepto**: El intervalo es de **1.2652** a **1.7494**, lo que nos indica que es significativo y no incluye 0, sugiriendo que hay un valor real positivo.

<!-- -->

-   **Coeficiente de `lcavol`**: El intervalo va de **0.5839** a **0.8547**, mostrando que `lcavol` tiene un efecto positivo y significativo sobre `lpsa`. Este resultado implica que un aumento en `lcavol` está asociado con un aumento en `lpsa`.

## 4.4 Definición de RSE y su valor.

El **Error Estándar de los Residuos (RSE)** es una medida de la cantidad de variabilidad de los residuos (la diferencia entre los valores observados y los valores predichos por el modelo) en un modelo de regresión lineal. Se utiliza para evaluar la precisión de las predicciones del modelo. Un RSE más bajo indica que el modelo tiene un mejor ajuste a los datos.

Matemáticamente, el RSE se define como:

$$
RSE = \sqrt{\frac{1}{n-2} \sum (y_i - \hat{y}_i)^2}
$$

donde:

-   $y_i$ son los valores observados,

-   $\hat{y}_i$ son los valores predichos por el modelo,

-   $n$ es el número de observaciones.

Si echamos un vistazo de nuevo a nuestro resultado:

```{r}
summary(modelo_lineal)
```

Un RSE de 0.7875 indica que, en promedio, las predicciones del modelo se desvían de los valores observados de la variable de respuesta (`lpsa`) en aproximadamente 0.7875 unidades en la escala logarítmica.

## 4.5 Estudio de la eficacia del modelo.

### **R-cuadrado (R²)**

El coeficiente de determinación $R^2$ es una métrica que indica la proporción de la varianza en la variable dependiente `lpsa` que es predecible a partir de la variable independiente `lcavol`. En este modelo, el $R^2$ es:

$R^2 = 0.5394$

-   **Interpretación**: Aproximadamente el 53.94% de la variabilidad en los niveles de PSA puede ser explicada por el volumen de cáncer. Esto sugiere una relación moderada entre las variables.

### **R-cuadrado Ajustado (Adjusted R²)**

El $R^2$ ajustado, que en este caso es:

$R^2$ Ajustado = 0.5346

-   **Interpretación**: El $R^2$ ajustado penaliza el $R^2$ por el número de predictores en el modelo, lo que lo hace más adecuado cuando se comparan modelos con diferentes números de variables. Este valor indica que el modelo tiene un ajuste similar al $R^2$, sugiriendo que el volumen de cáncer sigue siendo un predictor significativo.

### **Análisis de Varianza**

El estadístico F:

**F-estadístico = 111.3, p-valor \< 2.2e-16**

-   **Interpretación**: Este resultado indica que el modelo en su conjunto es significativamente mejor que un modelo sin variables predictivas (modelo nulo). Un p-valor extremadamente bajo sugiere que al menos una de las variables predictivas (en este caso, `lcavol`) es relevante para predecir `lpsa`.

### **Error Estándar de los Residuos (RSE)**

Como mencionamos anteriormente, el RSE es:

**RSE = 0.7875**

-   **Interpretación**: Este valor indica el tamaño promedio de los errores en las predicciones del modelo. Un RSE relativamente bajo en comparación con la variabilidad total en `lpsa` indica que el modelo tiene un buen ajuste.

### Resumen

En conjunto, el modelo de regresión lineal simple muestra una eficacia razonable para predecir los niveles de PSA en función del volumen de cáncer. La combinación de un $R^2$ moderado, un p-valor significativo y un RSE bajo sugiere que la relación entre `lcavol` y `lpsa` es relevante.

## 4. 6 Interpretación del Modelo Lineal (`psa` y `cavol`)

### **Ecuación del Modelo**

El modelo de regresión lineal simple que hemos calculado es:

$$ 
\text{lpsa} = 1.50730 + 0.71932 \times \text{lcavol} 
$$

### Relación entre PSA y cavol

1.  **Modelo Original**: La ecuación del modelo de regresión lineal que obtuvimos es: 
    $$
    \text{lpsa} = 1.50730 + 0.71932 \times \text{lcavol}
    $$

    $$
    ln(\text{psa}) = 1.50730 + 0.71932 \times ln(\text{cavol})
    $$

2.  **Despejar PSA**: Como $\text{lpsa}$ es el logaritmo natural del PSA, puedes deshacerte del logaritmo aplicando la función exponencial: 
    $$
    \text{PSA} = e^{ln(\text{psa})} = e^{(1.50730 + 0.71932 \times ln(\text{cavol}))}
    $$

    $$
    \text{PSA} = e^{1.50730 } + e^{(0.71932 \times ln(\text{cavol}))}
    $$

    $$
    \text{PSA} = e^{1.50730 } + (e^{ln(\text{cavol})})^{0.71932}
    $$

3.  **Transformación a `cavol`**: Para expresar esto en términos de `cavol` (el volumen de cáncer en su forma original), tienes que revertir el logaritmo: 
    $$
    \text{cavol} = e^{ln(\text{cavol})}
    $$

    Ahora sustituimos `lcavol` por su expresión en términos de `cavol`:

    $$
    \text{PSA} = e^{1.50730 } +\text{cavol}^{0.71932} 
    $$

4.  **Relación Final**: La relación entre `PSA` y `cavol` queda como: 
    $$
    \text{PSA} = C \cdot \text{cavol}^{b}
    $$ Donde $C = e^{1.50730}$ y $b = 0.71932$. Esto significa que `PSA` es proporcional a `cavol` elevado a un exponente.

### Interpretación de la Relación

-   **C**: Este es un coeficiente constante que representa el nivel de `PSA` cuando `cavol` es igual a 1 (o la unidad de referencia).
-   **b (0.71932)**: Indica que por cada aumento en el volumen de cáncer (`cavol`), el `PSA` aumenta en un porcentaje específico que depende del valor de `cavol`.

# 6. Modelo de Ridge y Lasso

Para realizar las predicciones usando los modelos de **Ridge** y **Lasso** utilizaremos la librería `glmnet`. Primero preparamos nuestro conjunto de datos lo dividimos entre el conjunto de **training** y el de **testeo**. Para crear nuestro training set utilizaremos el 70% de las entradas de nuestro conjunto de datos.

```{r}
library(glmnet)

# Preparamos un dataset sin las variables que no usamos
datos_usados <- subset(prostate, select = -c(age, pgg45, gleason))

# Dividimos el dataset entre predictores y el valor a predecir
X <- as.matrix(datos_usados[, -which(names(datos_usados) == "lpsa")])
y <- datos_usados$lpsa

# Creamos los conjuntos de train y test, especificando la seed para poder reproducir la ejecución
# con los mismos sets
set.seed(123) 
train_idx <- sample(1:nrow(X), size = 0.7 * nrow(X))
X.train <- X[train_idx,]
y.train <- y[train_idx]
X.test <- X[-train_idx,]
y.test <- y[-train_idx]
```

## Modelo de Ridge

Para utilizar el modelo de Ridge con `glmnet` debemos poner el parámetro $\alpha = 0$. Utilizaremos un *grid* con 200 valores de $\lambda$ diferentes, desde $10^{4}$ hasta $10^{-4}$. Estos valores se han determinado después de realizar la gráfica varias veces para asegurarnos de que las regiones que en ella se observan tienen una representación similar. A partir del modelo, podemos obtener el conjunto de coeficientes y los lambdas correspondientes a cada uno de los 200 modelos obtenidos.

```{r}
lambdas = 10^seq(4,-4, length = 200)

ridge.model <- glmnet(X.train, y.train, alpha = 0, lambda = lambdas)
# Obtenemos los coeficientes y los lambdas
ridge.coefs <- as.matrix(ridge.model$beta)
ridge.lambda <- ridge.model$lambda

matplot(log(ridge.lambda), t(ridge.coefs), type = "l", lty = 1, col = rainbow(nrow(ridge.coefs)),
        xlab = "log(λ)", ylab = "Coeficientes", main = "Ridge: Coeficientes vs log(λ)")
abline(v=log(lambda.min.ridge), col=4)
legend("topright", legend = colnames(X), col = rainbow(nrow(ridge.coefs)), lty = 1, cex = 0.6)
```

Vemos claramente 3 regiones en la gráfica. Una primera región a la izquierda, hasta $\log\lambda \approx (-\inf,-4)$, donde mientras el parámetro `lcp` tiene un coeficiente negativo, el resto de predictores tiene parámetros positivos. Una segunda región intermedia, aproximadamente entre $-4$ y $4$ donde estos valores varían, disminuyendo todos los coeficientes excepto el de `lcp`, que ahora crece y es positivo. Finaliza con una tercera región, donde los coeficientes convergen a un valor cercano a 0. El valor óptimo de $\lambda$ debería encontrarse en la zona intermedia de la gráfica, ya que no tendría demasiado sentido que el `lcp` tenga un coeficiente negativo en nuestra predicción.

Obtenemos el valor óptimo estimado de $\lambda$ usando validación cruzada, con la función `cv.glmnet` con el parámetro $\alpha=0$:

```{r}
# La seleccion hecha en el CV es tambien aleatoria, asi que debebemos especificar la 
# seed para asegurarnos de que podemos reprocir la prueba
set.seed(123) 
# Obtenemos el mejor valor de lambda usando cross-validation
cv.ridge.model <- cv.glmnet(X.train, y.train, alpha=0, lambda=lambdas)
lambda.min.ridge <- cv.ridge.model$lambda.min
log(lambda.min.ridge)
```

- Valor óptimo: $\lambda_\text{Ridge} = `r round(lambda.min.ridge,4)`$.
- Valor óptimo: $\log\lambda_\text{Ridge} = `r round(log(lambda.min.ridge),4)`$.

A continuación presentamos la gráfica del $MSE$ frente a $\log\lambda$ correspondiente al modelo de Ridge, indicando con una línea vertical azul la posición del $\lambda$ óptimo:

```{r}
plot(cv.ridge.model)
abline(v=log(lambda.min.ridge), col=4)
```

Vamos ahora a hacer la predicción de `lpsa` usando el conjunto de testeo.

```{r}
pred.ridge <- predict(cv.ridge.model, s = lambda.min.ridge, newx = X.test)
```

## Modelo de Lasso

Para utilizar el modelo de Lasso con `glmnet` debemos poner el parámetro $\alpha = 1$. Utilizaremos el mismo *grid* de \lambda usado para el modelo de *Ridge*, pero con valores de $\lambda$ entre $10^1$ y $10^{-4}$, valores que obtenemos de igual manera tras reproducir la gráfica varias veces. Después procedemos de forma similar.

```{r}
lambdas = 10^seq(1,-4, length = 200)
lasso.model <- glmnet(X.train, y.train, alpha = 1, lambda = lambdas)
# Obtenemos los coeficientes y los lambdas
lasso.coefs <- as.matrix(lasso.model$beta)
lasso.lambda <- lasso.model$lambda

matplot(log(lasso.lambda), t(lasso.coefs), type = "l", lty = 1, col = rainbow(nrow(lasso.coefs)),
        xlab = "log(λ)", ylab = "Coeficientes", main = "Lasso: Coeficientes vs log(λ)")
legend("topright", legend = colnames(X), col = rainbow(nrow(lasso.coefs)), lty = 1, cex = 0.6)
```

Podemos observar un gráfico similar al obtenido para *Ridge*, con la diferencia de que *Lasso* sí elimina predictores, es decir hace sus coeficientes 0. Contando esta diferencia, vemos también una representación análoga de las 3 regiones que vimos en el gráfico del modelo de *Ridge*, con una primera región donde el coeficiente de `lcp` es negativo, hasta que se elimina, una región intermedia donde se regulan el resto de parámetros, y una final donde se eliminan todos los coeficientes (en *Ridge* también tendían a 0). Es por esto que podemos suponer que, también en este caso, el valor óptimo de $\lambda$ se encontrará en la región intermedia.

También podemos visualizar el `plot` por defecto del modelo de *Lasso*, el cual nos muestra la evolución de los coeficientes con el `L1 Norm`, que representa el error que se intenta minimizar al utilizar este modelo:

$$
L1_\text{Norm} = RSS + \lambda \sum ^p_{j=1}|\beta_j|
$$

```{r}
plot(lasso.model, col = rainbow(nrow(lasso.coefs)))
legend("topright", legend = colnames(X), col = rainbow(nrow(lasso.coefs),start=0), lty = 1, cex = 0.6)
```


Obtenemos el valor óptimo estimado de $\lambda$ usando validación cruzada, con la función `cv.glmnet` con el parámetro $\alpha=1$:

```{r}
# La seleccion hecha en el CV es tambien aleatoria, asi que debebemos especificar la 
# seed para asegurarnos de que podemos reprocir la prueba
set.seed(123)
# Obtenemos el mejor valor de lambda usando cross-validation
cv.lasso.model <- cv.glmnet(X.train, y.train, alpha=1, lambda=lambdas)
lambda.min.lasso <- cv.lasso.model$lambda.min
lambda.min.lasso
```

- Valor óptimo: $\lambda_\text{Ridge} = `r round(lambda.min.lasso,4)`$.
- Valor óptimo: $\log\lambda_\text{Ridge} = `r round(log(lambda.min.lasso),4)`$.

A continuación presentamos la gráfica del $MSE$ frente a $\log\lambda$ correspondiente al modelo de Lasso, indicando con una línea vertical azul la posición del $\lambda$ óptimo:

```{r}
plot(cv.lasso.model)
abline(v=log(lambda.min.lasso), col=4)
```

Vamos ahora a hacer la predicción de `lpsa` usando el conjunto de testeo.

```{r}
pred.lasso <- predict(cv.lasso.model, s = lambda.min.lasso, newx = X.test)
```
