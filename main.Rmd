---
title: "Práctica de Aprendizaje Estadístico - Parte 1"
author: " "
date: "2024-10-30"
---

# 0. Carga los datos y elimina la variable TRAIN.

## 0.1 Configuración inicial. Carga de librerías.

**Nota: Nos aseguramos de tener el paquete `ElemStatLearn` instalado. Si no: `install.packages(lib_URL)`**

```{r}

lib_URL = 'https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/ElemStatLearn_2015.6.26.2.tar.gz'
install.packages(lib_URL)

library(ElemStatLearn)
library(dplyr)
```

Utilizamos `head()` para ver las primeras filas y hacernos una idea de las variables disponibles

```{r }

data("prostate", package = "ElemStatLearn")
head(prostate)

```

## 0.2 Eliminación de datos `TRAIN`.

La columna `train` se utiliza en estudios previos para indicar las filas de entrenamiento.

Dado que esta práctica no la requiere, eliminamos esta columna para simplificar el conjunto de datos.

```{r}

prostate = prostate %>% select(-train)
head(prostate)
```

# 1. Exploración de los datos

## 1.1 ¿Cuántas variables hay?

Tras eliminar la columna `train`, contamos con un total de `r length(prostate)` variables.

## 1.2 ¿De qué clase son?

Utilizamos la función `sapply` para aplicar una función, en este caso `class`, a todas las columnas.

```{r}
sapply(prostate, class)
```

Los tipos de las variables son del tipo `numeric` e `integer`, por lo que todos datos son números. Dado que son datos numéricos, podemos echar un vistazo a sus distribuciones.

```{r}
par(mfrow=c(3,3))
for (column in names(prostate)) {
  hist(prostate[[column]], main=paste("Histograma de", column), xlab = column)
}
```

Podemos observar que los valores de la variable `svi` se concentran en el 0 y en el 1, indicador de que esta variable podría ser un *booleano*. Veamos si estos son sus únicos valores.

```{r}
unique(prostate$svi)
```

0 y 1 son los únicos valores presentes, por lo que confirmaríamos que se trata de una variable *booleana* donde 1 indicaría que el cáncer ha invadido el vesículo seminal, y 0 indicaría lo contrario.

## 1.3 ¿Hay una variable que correspondiente al identificador de paciente? Si es así, elimínala.

No existe ninguna variable con el identificador del paciente.

## 1.4 ¿Hay valores nulos en alguno de los ficheros?

Averiguamos si existe algún valor nulo en todo el conjunto de datos. En caso de que lo haya, identificamos las columnas que los contienen.

```{r}
any(is.na(prostate))
```

Dado que no hay ningún valor nulo en nuestro set de datos, continuamos.

## ¿Están estandarizadas las variables? En este punto del análisis, ¿es necesario normalizarlas?

Tras revisar los histogramas realizados en el subapartado 2 podemos concluir que, dados los rangos de las variables y su disposición, estos no se encuentran normalizados.

## ¿Por qué crees que algunas variables están es escala logarítmica?

El objetivo de poner algunas de las variables en escala logarítmica es el de facilitar su posterior análisis por varios motivos:

-   Reducir la asimetría en casos en los que la distribución está muy sobrecargada en uno de sus extremos donde algunos valores excepcionales distorsionarían las estadísticas de la variable, haciendo que sus distribuciones se asemejen más a las de una distribución normal (como se observa en `lcavol`, `lweight` y `lpsa`).
-   Hacer que algunas variables se comporten de forma lineal cuando en escala natural no lo harían.

Además, cabe añadir que en los campos de la biología y la química es común usar escalas logarítmicas cuando estas hacen más fácil la interpretación de los datos.

# 2. Análisis de variables categóricas

Para convertir las variables `svi` y `gleason` a categóricas usamos la función `factor`.

```{r}
prostate$svi <- factor(prostate$svi, levels = c(0, 1), labels = c("No", "Yes"))
prostate$gleason <- factor(prostate$gleason)
```

A continuación, visualizamos las distribuciones usando gráficos de barras:

```{r}
par(mfrow = c(1, 2))  # Ajustar disposición gráfica
barplot(table(prostate$svi), main = "Distribución de SVI", col = "lightblue")
barplot(table(prostate$gleason), main = "Distribución de Gleason", col = "lightgreen")
```

Se puede observar como para la mayoría de pacientes se indica que el cáncer no ha invadido la vesícula seminal, a la par que la mayoría tiene un índice de Gleason de 6 o 7. Esto puede indicar cierta relación, ya que el índice de Gleason mide la agresividad del cáncer, por lo que índices más bajos indican cánceres menos agresivos. Podríamos aventurarnos a pensar que la mayoría de cánceres agresivos no llegarían a infectar la vesícula seminal.

En el caso de la variable **Edad** queremos hacer una agrupación cada 5 años, por lo que usaremos la función `cut` para generar esas categorías:

```{r}
max.age = max(prostate$age)
min.age = min(prostate$age)
# Añadimos +5 al maximo para que el rango tome tambien el ultimo grupo
prostate$age <- cut(prostate$age, breaks = seq(from=min.age, to=max.age+5, by=5), right=FALSE)
barplot(table(prostate$age), main = "Distribución de Edad", col = "salmon", width = 3)
```

En el caso de la edad nos encontramos una distribución que podría recordar a la normal, centrada en los 65 años, encontrándose el grueso de la distribución entre los 61 y 70 años. Cabe añadir que encontramos casos desde los `r min.age` hasta los `r max.age` años.

# 4. Regresión lineal simple.

Análisis de la dependencia lineal de la variable `lpsa` con la variable `lcavol`.

```{r}
library(dplyr)
library(ggplot2)
```

Ajustamos el modelo y vemos su `summary()`:

```{r}
modelo_lineal <- lm(lpsa ~ lcavol, data = prostate)

summary(modelo_lineal)
```

## 4.1 Interpretación del Modelo Lineal calculado

### Ecuación del Modelo

La ecuación del modelo de regresión lineal es:

$$
\text{lpsa} = 1.50730 + 0.71932 \cdot \text{lcavol}
$$

### Intercepto ($\beta_0$)

-   El intercepto de **1.50730** indica el valor estimado de `lpsa` cuando `lcavol` es igual a 0.

### Pendiente ($\beta_1$)

-   El coeficiente para `lcavol` es **0.71932**. Esto sugiere que, por cada unidad de incremento en `lcavol`, se espera que `lpsa` aumente en aproximadamente **0.71932** unidades.

### Residuos

-   Estadísticas de los residuos:
    -   **Mínimo**: -1.67624
    -   **Máximo**: 1.89672
-   Esto indica variaciones en los errores de predicción.

### Error Estándar de los Residuos

-   El error estándar de los residuos es **0.7875**, indicando que las predicciones están, en promedio, a **0.7875** unidades de `lpsa` de los valores reales.

### R-squared (R²)

-   El $R^2$ múltiple es **0.5394**, lo que significa que aproximadamente el **53.94%** de la variabilidad en `lpsa` se puede explicar por la variabilidad en `lcavol`.

### F-statistic

-   El valor de la estadística F es **111.3** con un valor p-value a **2.2e-16**, indicando que al menos uno de los predictores tiene un efecto significativo en `lpsa`.

### Conclusión

En resumen, el modelo de regresión lineal simple muestra que hay una relación positiva y significativa entre `lcavol` y `lpsa`. A medida que el logaritmo del volumen del cáncer (`lcavol`) aumenta, también se espera que el logaritmo del antígeno prostático específico (`lpsa`) aumente. El modelo es estadísticamente significativo.

## 4.2 Plot de los datos junto a la recta de regresión.

Crearemos una gráfico de dispersión de `lcavol` vs `lpsa`.

```{r}
ggplot(prostate, 
       aes(x = lcavol, y = lpsa)) +
  
 # Puntos de los datos
geom_point(color = "blue", 
           alpha = 0.4) +

# Recta de regresión
geom_smooth(method = "lm", 
            color = "red") + 
  
labs(title = "Relación entre lcavol y lpsa",
     x = "Log de Volumen de Cáncer (lcavol)",
     y = "Log de Antígeno Prostático Específico (lpsa)") +
  
theme_minimal()
```

## 4.3 Intervalos de confianza para los coeficientes del modelo con una confianza de 0.95.

Los intervalos de confianza al 95% para los coeficientes del modelo son importantes para entender la precisión de las estimaciones. A continuación se presentan los intervalos calculados:

```{r}
confint(modelo_lineal, level = 0.95)
```

-   **Intercepto**: El intervalo es de **1.2652** a **1.7494**, lo que nos indica que es significativo y no incluye 0, sugiriendo que hay un valor real positivo.

<!-- -->

-   **Coeficiente de `lcavol`**: El intervalo va de **0.5839** a **0.8547**, mostrando que `lcavol` tiene un efecto positivo y significativo sobre `lpsa`. Este resultado implica que un aumento en `lcavol` está asociado con un aumento en `lpsa`.

## 4.4 Definición de RSE y su valor.

El **Error Estándar de los Residuos (RSE)** es una medida de la cantidad de variabilidad de los residuos (la diferencia entre los valores observados y los valores predichos por el modelo) en un modelo de regresión lineal. Se utiliza para evaluar la precisión de las predicciones del modelo. Un RSE más bajo indica que el modelo tiene un mejor ajuste a los datos.

Matemáticamente, el RSE se define como:

$$
RSE = \sqrt{\frac{1}{n-2} \sum (y_i - \hat{y}_i)^2}
$$

donde:

-   $y_i$ son los valores observados,

-   $\hat{y}_i$ son los valores predichos por el modelo,

-   $n$ es el número de observaciones.

Si echamos un vistazo de nuevo a nuestro resultado:

```{r}
summary(modelo_lineal)
```

Un RSE de 0.7875 indica que, en promedio, las predicciones del modelo se desvían de los valores observados de la variable de respuesta (`lpsa`) en aproximadamente 0.7875 unidades en la escala logarítmica.

## 4.5 Estudio de la eficacia del modelo.

### **R-cuadrado (R²)**

El coeficiente de determinación $R^2$ es una métrica que indica la proporción de la varianza en la variable dependiente `lpsa` que es predecible a partir de la variable independiente `lcavol`. En este modelo, el $R^2$ es:

$R^2 = 0.5394$

-   **Interpretación**: Aproximadamente el 53.94% de la variabilidad en los niveles de PSA puede ser explicada por el volumen de cáncer. Esto sugiere una relación moderada entre las variables.

### **R-cuadrado Ajustado (Adjusted R²)**

El $R^2$ ajustado, que en este caso es:

$R^2$ Ajustado = 0.5346

-   **Interpretación**: El $R^2$ ajustado penaliza el $R^2$ por el número de predictores en el modelo, lo que lo hace más adecuado cuando se comparan modelos con diferentes números de variables. Este valor indica que el modelo tiene un ajuste similar al $R^2$, sugiriendo que el volumen de cáncer sigue siendo un predictor significativo.

### **Análisis de Varianza**

El estadístico F:

**F-estadístico = 111.3, p-valor \< 2.2e-16**

-   **Interpretación**: Este resultado indica que el modelo en su conjunto es significativamente mejor que un modelo sin variables predictivas (modelo nulo). Un p-valor extremadamente bajo sugiere que al menos una de las variables predictivas (en este caso, `lcavol`) es relevante para predecir `lpsa`.

### **Error Estándar de los Residuos (RSE)**

Como mencionamos anteriormente, el RSE es:

**RSE = 0.7875**

-   **Interpretación**: Este valor indica el tamaño promedio de los errores en las predicciones del modelo. Un RSE relativamente bajo en comparación con la variabilidad total en `lpsa` indica que el modelo tiene un buen ajuste.

### Resumen

En conjunto, el modelo de regresión lineal simple muestra una eficacia razonable para predecir los niveles de PSA en función del volumen de cáncer. La combinación de un $R^2$ moderado, un p-valor significativo y un RSE bajo sugiere que la relación entre `lcavol` y `lpsa` es relevante.

## 4. 6 Interpretación del Modelo Lineal (`psa` y `cavol`)

### **Ecuación del Modelo**

El modelo de regresión lineal simple que hemos calculado es:

$$ 
\text{lpsa} = 1.50730 + 0.71932 \times \text{lcavol} 
$$

### Relación entre PSA y cavol

1.  **Modelo Original**: La ecuación del modelo de regresión lineal que obtuvimos es:

    $$
    \text{lpsa} = 1.50730 + 0.71932 \times \text{lcavol}
    $$

    $$
    ln(\text{psa}) = 1.50730 + 0.71932 \times ln(\text{cavol})
    $$

2.  **Despejar PSA**: Como $\text{lpsa}$ es el logaritmo natural del PSA, puedes deshacerte del logaritmo aplicando la función exponencial:

    $$
    \text{PSA} = e^{ln(\text{psa})} = e^{(1.50730 + 0.71932 \times ln(\text{cavol}))}
    $$

    $$
    \text{PSA} = e^{1.50730 } + e^{(0.71932 \times ln(\text{cavol}))}
    $$

    $$
    \text{PSA} = e^{1.50730 } + (e^{ln(\text{cavol})})^{0.71932}
    $$

3.  **Transformación a `cavol`**: Para expresar esto en términos de `cavol` (el volumen de cáncer en su forma original), tienes que revertir el logaritmo:

    $$
    \text{cavol} = e^{ln(\text{cavol})}
    $$

    Ahora sustituimos `lcavol` por su expresión en términos de `cavol`:

    $$
    \text{PSA} = e^{1.50730 } +\text{cavol}^{0.71932} 
    $$

4.  **Relación Final**: La relación entre `PSA` y `cavol` queda como:

    $$
    \text{PSA} = C \cdot \text{cavol}^{b}
    $$ Donde $C = e^{1.50730}$ y $b = 0.71932$. Esto significa que `PSA` es proporcional a `cavol` elevado a un exponente.

### Interpretación de la Relación

-   **C**: Este es un coeficiente constante que representa el nivel de `PSA` cuando `cavol` es igual a 1 (o la unidad de referencia).
-   **b (0.71932)**: Indica que por cada aumento en el volumen de cáncer (`cavol`), el `PSA` aumenta en un porcentaje específico que depende del valor de `cavol`.

# 5. Regresión lineal múltiple.

## 5.1 Observación de correlaciones entre variables.

```{r}
library(corrplot)

cor_data = prostate %>% select(-age, -pgg45, -gleason, -svi)

cor_matrix <- cor(cor_data)

# Quitamos las relaciones (x, x), puede ser menos intuitiva de interpretar, pero
# los colores consiguen ser más descriptivos.
corrplot(cor_matrix, 
         diag = FALSE, 
         method = "circle", 
         type = "upper", 
         tl.col = "black", 
         tl.srt = 25, 
         title = "Matriz de Correlación entre Variables")

print(cor_matrix)
```

La matriz de correlación muestra las correlaciones de Pearson entre las variables del conjunto de datos, con valores que van de -1 a 1.

### Análisis de la Matriz de Correlación

Se ha realizado un análisis de correlación entre las variables del conjunto de datos, excluyendo las siguientes variables: **`age`**, **`pgg45`**, **`gleason`**, y **`svi`**. Las variables consideradas son: **`lcavol`**, **`lweight`**, **`lbph`**, **`lcp`**, y **`lpsa`**. A continuación se presentan los resultados y las interpretaciones:

1.  **`lcavol`**:
    -   **Máxima correlación**: `lpsa` (0.734).
    -   **Interpretación**: La fuerte correlación entre el volumen del cáncer en escala logarítmica (`lcavol`) y el nivel de antígeno específico de la próstata (PSA) sugiere que a medida que aumenta el volumen del cáncer, también tienden a aumentar los niveles de PSA.
2.  **`lpsa`**:
    -   **Máxima correlación**: `lcavol` (0.734).
    -   **Interpretación**: Refuerza la conexión entre el nivel de PSA y el volumen del cáncer. Esto implica que los médicos pueden utilizar el PSA como un indicador indirecto del volumen tumoral y, por lo tanto, de la severidad del cáncer.
3.  **`lweight`**:
    -   **Máxima correlación**: `lbph` (0.442).
    -   **Interpretación**: La correlación entre el peso en escala logarítmica (`lweight`) y la hipertrofia benigna de próstata (`lbph`) indica que hay una relación positiva entre ambos. Esto sugiere que los hombres con mayor peso pueden tener mayor riesgo de desarrollar condiciones benignas en la próstata.
4.  **`lbph`**:
    -   **Máxima correlación**: `lweight` (0.442).
    -   **Interpretación**: Similar a lo mencionado anteriormente, esta correlación sugiere que el aumento de peso podría estar relacionado con la aparición de hipertrofia benigna, sugiriendo un vínculo en la salud prostática.
5.  **`lcp`**:
    -   **Máxima correlación**: `lcavol` (0.675).
    -   **Interpretación**: La correlación entre los niveles de PSA en escala logarítmica (`lcp`) y el volumen del cáncer (`lcavol`) indica que a mayor volumen tumoral, los niveles de PSA también tienden a ser más altos. Esto es importante para evaluar la progresión del cáncer y determinar el tratamiento adecuado.
6.  **Conclusiones generales**:
    -   Se observa que `lcavol` y `lpsa` están fuertemente correlacionados, lo que resalta su importancia en el diagnóstico y seguimiento del cáncer de próstata.
    -   La relación entre `lweight` y `lbph` sugiere que los factores de estilo de vida pueden influir en la salud prostática.
    -   La correlación entre `lcp` y `lcavol` enfatiza la conexión entre el volumen del tumor y los niveles de PSA, lo cual es relevante para la prognosis clínica.

# 5.2 Modelo de regresión lineal para predecir `lpsa`.

```{r}
modelo_lpsa <- lm(lpsa ~ lcavol + lweight + lbph + lcp, data = prostate)

summary(modelo_lpsa)
```

1.  **Coeficientes**:

-   **Intercepto**: -0.42786 (no es significativo, p = 0.5600).

-   **`lcavol`**: 0.58479 (muy significativo, p = 3.65e-09). Esto indica que, manteniendo las otras variables constantes, un aumento de una unidad en `lcavol` se asocia con un aumento de 0.58479 unidades en `lpsa`.

-   **`lweight`**: 0.58630 (significativo, p = 0.0055). Al igual que `lcavol`, un aumento de una unidad en `lweight` también se asocia con un incremento en `lpsa`, lo que sugiere que el peso del paciente puede influir en los niveles de PSA.

-   **`lbph`**: 0.05412 (no significativo, p = 0.3571). Esto sugiere que la hipertrofia benigna de próstata no tiene un efecto significativo en los niveles de PSA.

-   **`lcp`**: 0.09102 (no significativo, p = 0.2178). Similar a `lbph`, no parece tener un efecto significativo en `lpsa`.

2.  **Residuals**:

-   Los residuos tienen un rango que va desde -1.55078 hasta 1.78086, con un valor mediano cercano a cero, lo que indica que el modelo está relativamente equilibrado en cuanto a sus predicciones.

3.  **R-squared**:

-   **Multiple R-squared**: 0.6056. Esto significa que aproximadamente el 60.56% de la variación en `lpsa` puede ser explicada por las variables independientes (`lcavol`, `lweight`, `lbph`, `lcp`).

-   **Adjusted R-squared**: 0.5884. Este valor ajustado es ligeramente inferior, lo que sugiere que el modelo tiene un ajuste razonable, pero que podría no ser óptimo dado el número de variables en comparación con el número de observaciones.

4.  **F-statistic**: 35.31 (p \< 2.2e-16). Esto indica que, en general, al menos una de las variables independientes es significativamente diferente de cero, lo que sugiere que el modelo tiene validez.

## Conclusiones

1.  **Significancia de las variables**:

-   Las variables `lcavol` y `lweight` son estadísticamente significativas y tienen un efecto positivo en `lpsa`. Sin embargo, `lbph` y `lcp` no son significativos y no parecen influir en `lpsa`.

2.  **Eficacia del modelo**:

-   El modelo tiene un R² ajustado de aproximadamente 0.59, lo que indica que, aunque hay una correlación significativa con `lpsa`, hay un 40% de la variación que no se explica por las variables incluidas. Esto sugiere que pueden existir otros factores que influyen en `lpsa` que no están siendo considerados en el modelo actual.

3.  **Limitaciones**:

-   La significancia de las variables se centra en `lcavol` y `lweight`, lo que puede señalar la necesidad de explorar más a fondo el impacto de estas variables en el contexto del cáncer de próstata.

-   Podría ser útil considerar la inclusión de variables adicionales que podrían mejorar el ajuste del modelo o explorar interacciones entre variables.

4.  **Recomendaciones**:

-   Realizar un análisis de residuales para evaluar supuestos del modelo como la homocedasticidad y la normalidad.

-   Considerar un análisis de multicolinealidad para asegurarse de que no haya problemas entre las variables independientes.

En general, el modelo ofrece información valiosa sobre los determinantes de `lpsa`, pero hay margen de mejora en términos de ajuste y comprensión de los factores que contribuyen a esta variable.
